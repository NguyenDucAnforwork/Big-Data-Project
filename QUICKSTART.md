# ğŸš€ NYC Taxi Analytics - Quick Start

## Khá»Ÿi Ä‘á»™ng Pipeline (1 lá»‡nh)

```bash
./start-pipeline.sh
```

**Äá»£i 2-3 phÃºt** cho Ä‘áº¿n khi tháº¥y: `Pipeline is ready for demo! ğŸš€`

---

## Cháº¡y Demo

### 1. Start Producer (Terminal má»›i)

```bash
uv run python kafka/producer.py
```

Sáº½ stream 1000 records (~50 giÃ¢y)

### 2. Kiá»ƒm tra dá»¯ liá»‡u

```bash
# Äáº¿m sá»‘ records trong Cassandra
./query-cassandra.sh count

# Xem dá»¯ liá»‡u gáº§n Ä‘Ã¢y
./query-cassandra.sh recent

# Top zones theo revenue
./query-cassandra.sh zones
```

### 3. Xem Dashboard

Má»Ÿ trÃ¬nh duyá»‡t: http://localhost:3000

- **User:** admin
- **Pass:** admin

---

## Dá»«ng Pipeline

```bash
./stop-pipeline.sh
```

---

## Náº¿u cÃ³ lá»—i

### Cassandra khÃ´ng connect Ä‘Æ°á»£c

```bash
docker exec cassandra nodetool status
docker cp cassandra/init.cql cassandra:/tmp/init.cql
docker exec cassandra cqlsh -f /tmp/init.cql
```

### Grafana khÃ´ng login Ä‘Æ°á»£c

```bash
docker compose down
docker volume rm big-data-project_grafana_data
./start-pipeline.sh
```

### Spark bá»‹ crash

```bash
# XÃ³a checkpoints
rm -rf /tmp/spark_checkpoints/*

# Restart Spark
pkill -f spark-submit
./start-pipeline.sh
```

---

## Monitoring

```bash
# Spark logs
tail -f spark_streaming.log

# Kafka messages
docker exec broker kafka-console-consumer.sh \
  --bootstrap-server localhost:9092 \
  --topic taxi-trips --max-messages 5

# Docker resource usage
docker stats --no-stream
```

---

## Kiáº¿n trÃºc

```
Parquet Data â†’ Producer â†’ Kafka â†’ Spark Streaming â†’ Cassandra â†’ Grafana
```

- **Window:** 5 phÃºt
- **Metrics:** 9 aggregations
- **Latency:** < 30 giÃ¢y

ğŸ“– **Chi tiáº¿t:** Xem `DEMO-GUIDE.md`
